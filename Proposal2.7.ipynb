{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e58fe91-3e39-4710-a18d-e04a7a8ddadf",
   "metadata": {},
   "source": [
    "# Project Proposal: Predicting the Popularity of YouTube Videos Using Early Metrics\n",
    "\n",
    "## 1. Problem Description and Motivation (2%)\n",
    "\n",
    "We want to predict how popular YouTube videos will be using early engagement metrics. YouTube's algorithm usually recommends videos based on early stats like views, likes, comments, and shares. But figuring out *which specific factors* have the biggest impact on whether a video goes viral can offer important insights for creators, marketers, and viewers.\n",
    "\n",
    "**Motivation**: With billions of videos on YouTube, knowing which ones will become popular early on can be super helpful for improving content strategy. This project will help people (and me! i have a pathetic youtube channel that nobody seems to notice) predict whether a video will be a hit by analyzing early data (like view count) .\n",
    "\n",
    "This is my channel i hope my project will help it one day :( ..... \n",
    "https://www.youtube.com/channel/UC91T6l13DPKKHhLMF10Gi2g?sub_confirmation=1\n",
    "\n",
    "We’re focusing on two key questions:\n",
    "1. **Which early engagement metrics (views, likes, comments) have the biggest influence on a video’s future success?**\n",
    "2. **Can we accurately predict the future view count of a video using data from its first 24 hours?**\n",
    "\n",
    "This project taps into the growing role of video content in today’s digital world and could be a valuable tool for content creators looking to improve their strategies.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b40d1-1622-4fb0-8544-1e1b3e4f68c7",
   "metadata": {},
   "source": [
    "## 2. Data Source and Collection Plan (2%)\n",
    "\n",
    "For this project, we’ll gather data using the **YouTube Data API**(very unfortunately it only allows us to collect `1500` videos per day. That's why i've consecutively collected datas for the past week so if you pick my proposal we will start with about at least `4500` videos. yay!). We’ll focus on videos uploaded in the last 30 days from a specific category (e.g., \"Data Science Tutorial\") to keep the data fresh and relevant.\n",
    "\n",
    "**Features we’ll collect:**\n",
    "- **Numeric Features**: View Count, Like Count, Comment Count\n",
    "- **Categorical Feature**: Video Category (e.g., \"Education,\" \"Science & Technology\")\n",
    "\n",
    "**Data Collection**: \n",
    "We’ll use Python and the YouTube Data API to collect the data. Each API call will retrieve up to 50 videos, and we’ll paginate through the results if needed. The data will be focused on engagement metrics ( we may later decide if we want the data to be collected only from the first 24 hours after the video is released by changing code here:  for day in range(days):  # Now we loop through each day to collect data\n",
    "        # We need to format the start and end dates correctly for YouTube's API\n",
    "        start_date = (today - timedelta(days=day+1)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end_date = (today - timedelta(days=day)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        )  We’ll map category IDs to their actual names to make the data easier to understand.\n",
    "\n",
    "We’ll store the data in a CSV file with the following columns:\n",
    "- `Video ID`: Unique identifier for each video\n",
    "- `View Count`: Number of views the video has received\n",
    "- `Like Count`: Number of likes\n",
    "- `Comment Count`: Number of comments\n",
    "- `Video Category`: The category the video belongs to\n",
    "- `Video Published At`: The date and time the video was published\n",
    "\n",
    "**I've paste my code below for ur referennce**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11381ce5-7293-424b-83f2-e369e1c8e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /opt/miniconda3/lib/python3.12/site-packages (2.147.0)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (2.35.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (2.20.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.28.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.24.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/miniconda3/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/miniconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535eda5-1b74-4d70-9315-3a85d45f5fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514d2165-63f4-41b3-8392-e8a63b1abb30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43013189-d456-4707-86f2-e64e3640a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection complete. Saved to YP_Youtube_50_Videos.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# Here's where I'm putting my YouTube API key. \n",
    "# (pls don't share it with others i have number limits every day on the videos i can pull off)\n",
    "API_KEY = \"AIzaSyDOg4YBSWnZkOdsb67hDOVRsHuCht3TVDg\"  \n",
    "\n",
    "# Now we initialize the YouTube API client with the API key so we can make requests\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "# Next, let's write a function to fetch videos based on a search query\n",
    "def get_videos(query, max_results=50, published_after=None, next_page_token=None):\n",
    "    \"\"\"\n",
    "    This function will fetch videos from YouTube based on the query we pass in.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The search term to find relevant videos.\n",
    "        max_results (int): The maximum number of videos to get in one request.\n",
    "        published_after (str): Only fetch videos published after this timestamp (formatted in RFC 3339).\n",
    "        next_page_token (str): Here we use pagination to fetch more videos, if available.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): This will return the YouTube response with video data.\n",
    "    \"\"\"\n",
    "    request = youtube.search().list(\n",
    "        q=query,  # Here we set the search term\n",
    "        part=\"snippet\",  # Now we can get the basic info about each video (like title, channel, etc.)\n",
    "        type=\"video\",  # This will get only videos (not channels or playlists)\n",
    "        maxResults=max_results,  # This controls how many videos we’re requesting in this call\n",
    "        publishedAfter=published_after,  # Only fetch videos after a certain date\n",
    "        order=\"date\",  # Sort by the latest videos\n",
    "        pageToken=next_page_token  # If there are more pages, this will help us get the next set of results\n",
    "    )\n",
    "    response = request.execute()  # Now we execute the request to YouTube\n",
    "    return response  # Here we return the fetched video data\n",
    "\n",
    "# Now we can write a function to get the stats for each video (e.g., views, likes, comments)\n",
    "def get_video_statistics(video_ids):\n",
    "    \"\"\"\n",
    "    This function will grab all the stats for the videos we found, including category information.\n",
    "    \n",
    "    Parameters:\n",
    "        video_ids (list): A list of video IDs for which to get statistics.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): This returns the video statistics and metadata from YouTube.\n",
    "    \"\"\"\n",
    "    request = youtube.videos().list(\n",
    "        part=\"statistics, snippet\",  # Now we can fetch both statistics (views, likes) and snippet (title, category)\n",
    "        id=\",\".join(video_ids)  # Here we join the video IDs into a single string separated by commas\n",
    "    )\n",
    "    response = request.execute()  # Now we execute the request to get the stats\n",
    "    return response  # Finally, we return the response containing video stats\n",
    "\n",
    "# This is the main function that collects video data up to a maximum of 50 videos\n",
    "def collect_video_data(query, max_results_total=50, max_results_per_page=50):\n",
    "    \"\"\"\n",
    "    Here we collect video data for a specific search query, collecting up to max_results_total videos\n",
    "    published within the last 24 hours.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The search query to find relevant videos.\n",
    "        max_results_total (int): The total number of videos to collect.\n",
    "        max_results_per_page (int): Maximum videos to fetch per request.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Now we’ll return a DataFrame with all the collected video statistics and metadata.\n",
    "    \"\"\"\n",
    "    video_data = []\n",
    "    total_videos_collected = 0  # Track the total number of videos collected\n",
    "    next_page_token = None  # Initialize the page token for pagination\n",
    "    \n",
    "    # Get the current time and subtract 24 hours to get the time range for the last 24 hours\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    published_after = (current_time - timedelta(days=1)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")  # 24 hours ago in RFC 3339 format\n",
    "    \n",
    "    # Loop until we reach max_results_total videos\n",
    "    while total_videos_collected < max_results_total:\n",
    "        # Fetch videos published within the last 24 hours\n",
    "        response = get_videos(query, max_results=max_results_per_page, published_after=published_after, next_page_token=next_page_token)\n",
    "        \n",
    "        video_ids = [item['id']['videoId'] for item in response.get('items', [])]  # Extract video IDs from the response\n",
    "        \n",
    "        if not video_ids:\n",
    "            break  # If no more videos are found, we stop the loop\n",
    "        \n",
    "        # Get statistics for the fetched videos\n",
    "        stats_response = get_video_statistics(video_ids)\n",
    "        \n",
    "        # Loop through each video and collect the data\n",
    "        for item in stats_response.get('items', []):\n",
    "            video_id = item['id']\n",
    "            statistics = item['statistics']  # Get the statistics like views, likes, etc.\n",
    "            snippet = item['snippet']  # Get the metadata like title, category, etc.\n",
    "            \n",
    "            # Append the collected data for each video\n",
    "            video_data.append({\n",
    "                'Video ID': video_id,\n",
    "                'View Count': int(statistics.get('viewCount', 0)),  # Ensure view count is an integer, defaulting to 0 if missing\n",
    "                'Like Count': int(statistics.get('likeCount', 0)),  # Same for like count\n",
    "                'Comment Count': int(statistics.get('commentCount', 0)),  # Same for comment count\n",
    "                'Favorite Count': int(statistics.get('favoriteCount', 0)),  # Handle favorite count similarly\n",
    "                'Video Category': snippet.get('categoryId', 'Unknown'),  # Store the category ID as a feature\n",
    "                'Video Published At': snippet.get('publishedAt', 'Unknown')  # Store the publication date\n",
    "            })\n",
    "        \n",
    "        # Update the total number of videos collected\n",
    "        total_videos_collected += len(video_ids)\n",
    "        \n",
    "        # Check if we have reached the max results or no more pages to fetch\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token or total_videos_collected >= max_results_total:\n",
    "            break\n",
    "    \n",
    "    # Finally, convert the list of video data into a DataFrame\n",
    "    return pd.DataFrame(video_data[:max_results_total])\n",
    "\n",
    "# Now we can use all of this to collect data and save it to a CSV\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Youtube\"  # Set the search term to something relevant (e.g., \"Data Science Tutorial\")\n",
    "    max_videos = 50  # Collect up to 50 videos in total\n",
    "    \n",
    "    # Time to collect our video data\n",
    "    df = collect_video_data(query, max_results_total=max_videos)\n",
    "    \n",
    "    # Now we save the collected data to a CSV file\n",
    "    df.to_csv('YP_Youtube_50_Videos.csv', index=False)\n",
    "    print(\"Data collection complete. Saved to YP_Youtube_50_Videos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01fb9887-5db1-40ef-a857-36731004ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
      "0  _87rquuvcg4           0           0              0               0   \n",
      "1  ibqkMQN4RyQ          20           2              2               0   \n",
      "2  tya2UOzu6aM           1           0              0               0   \n",
      "3  XtqSNNmpk7M          16           3              0               0   \n",
      "4  29sjCAqOVLw           7           3              0               0   \n",
      "\n",
      "   Video Category    Video Published At  \n",
      "0              25  2024-10-21T04:21:53Z  \n",
      "1              27  2024-10-20T16:01:15Z  \n",
      "2              27  2024-10-20T12:45:06Z  \n",
      "3              28  2024-10-20T11:30:18Z  \n",
      "4              27  2024-10-20T10:40:10Z  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fcdcd-8a7e-4475-a60d-cdbf68785a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b5779-453a-43b9-83b5-7fbf6e7937d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7018a4-654c-4412-9ec3-c9f88f927f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b62008-5c9a-4083-ac34-0b320b413cbc",
   "metadata": {},
   "source": [
    "While gathering the data from YouTube, I encountered an issue where the \"Video Category\" field was returned in numerical format. These numerical category IDs aren't very helpful for understanding what each category represents. I dopn't think the youtube API i am using natively support category names.\n",
    "\n",
    "To make the data more meaningful and readable, we need to map these numerical category IDs to their actual category names (e.g., '27' becomes 'Education', '28' becomes 'Science & Technology', and so on).\n",
    "\n",
    "In the next step, I create a dictionary to map these numerical IDs to their corresponding names, then apply this mapping to the dataset so that the \"Video Category\" field reflects the actual category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b1f7f15-2903-4a5a-9e2f-8ce5f28d895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category mapping completed. Saved to YP_Youtube_50_Videos.csv\n"
     ]
    }
   ],
   "source": [
    "# Now, we're going to create a dictionary to map those category IDs to actual category names. \n",
    "# This way, we can easily understand what each category represents.\n",
    "category_mapping = {\n",
    "    '1': 'Film & Animation',\n",
    "    '2': 'Autos & Vehicles',\n",
    "    '10': 'Music',\n",
    "    '15': 'Pets & Animals',\n",
    "    '17': 'Sports',\n",
    "    '18': 'Short Movies',\n",
    "    '19': 'Travel & Events',\n",
    "    '20': 'Gaming',\n",
    "    '21': 'Videoblogging',\n",
    "    '22': 'People & Blogs',\n",
    "    '23': 'Comedy',\n",
    "    '24': 'Entertainment',\n",
    "    '25': 'News & Politics',\n",
    "    '26': 'Howto & Style',\n",
    "    '27': 'Education',\n",
    "    '28': 'Science & Technology',\n",
    "    '29': 'Nonprofits & Activism'\n",
    "    # More categories can be added here if needed, but this should cover the most common ones. I didn't find a better list/map yet if  you do you  can add here\n",
    "}\n",
    "\n",
    "# Now let's load the CSV file that contains our YouTube video data.\n",
    "# This file has all the video details that we collected earlier.\n",
    "df = pd.read_csv('YP_Youtube_50_Videos.csv')\n",
    "\n",
    "# Here's where the transformation happens. We're going to replace the category IDs with the actual names.\n",
    "# First, we make sure the 'Video Category' column is in string format, then we map those IDs to the category names.\n",
    "df['Video Category'] = df['Video Category'].astype(str).map(category_mapping)\n",
    "\n",
    "# Now that we've updated the data, let's save it to a new CSV file.\n",
    "# This way, the original data stays untouched, and we get a more readable version with category names.\n",
    "df.to_csv('YP_Youtube_50_Videos.csv', index=False)\n",
    "\n",
    "# Finally, let's print a message to confirm that everything worked and the file was saved successfully.\n",
    "print(\"Category mapping completed. Saved to YP_Youtube_50_Videos.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22c2c6-c344-4c35-903a-479ef0109063",
   "metadata": {},
   "source": [
    "  ## 3. How the Data Will Be Used and Questions of Interest (1%)\n",
    "\n",
    "Once we have the data, we’ll analyze how early engagement metrics relate to a video’s future popularity. Specifically, we’ll focus on:\n",
    "\n",
    "- **Predicting View Counts**: Using the early metrics (views, likes, comments), we’ll try to predict how many views a video will get in the future (like a week later). By building a machine learning model, we’ll look for patterns that can predict future video performance.\n",
    "  \n",
    "- **Identifying Key Metrics**: We’ll also try to figure out which engagement metric has the biggest influence on a video’s popularity. For example, is the number of comments more important than the number of likes?\n",
    "\n",
    "The goal is to create a model that helps us understand and predict how successful a video will be based on its early performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This project dives into the growing trend of using early data to predict video success on YouTube. By collecting and analyzing video data over time, we hope to uncover useful insights for content creators and marketers. Plus, it’s a great way to apply machine learning techniques to real-world data from one of the biggest video platforms in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb577fc3-c430-4f8f-9d0f-809e978dc9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
      "0   id0-2uhkaU0       10763        1700             39               0   \n",
      "1   M79F47l-qYc        6884         889             18               0   \n",
      "2   uDVNRYxIMRE       67897         332              0               0   \n",
      "3   Yfcs9OPrQz8       34864         340              0               0   \n",
      "4   H_1-uFgQrrg      127473       10765             76               0   \n",
      "5   OapndFASEvk       30654         502              9               0   \n",
      "6   VET1qKCyq4c      259325       12911            107               0   \n",
      "7   NUzGaZkGTu4       70507         381              0               0   \n",
      "8   I1cPbwuMc3U      228437         622              2               0   \n",
      "9   E98wLBO1v4I      107973        7895             17               0   \n",
      "10  RzQpDaa2044     2134518       30997             21               0   \n",
      "11  GN0r5_ynJ9A      287976       17923            124               0   \n",
      "12  _D3_9kIFUMs        7357        2941              0               0   \n",
      "13  ihtUyR9qjEs        9660         440            352               0   \n",
      "14  6iG4Zp8HLOA      192437        4111              0               0   \n",
      "15  p8SIBaDl9PE       30625         812              0               0   \n",
      "16  IPwVtRypNbI      278834        1377              6               0   \n",
      "17  paTQ-p8K0BA      150555        1246              4               0   \n",
      "18  YhKkv5-4KAg      147921         856              0               0   \n",
      "19  oUyle9aTwdI      391328        1965             30               0   \n",
      "20  LqIo3IwSWPY        2897          80              0               0   \n",
      "21  Mq2M3Bz8zz0      212149        4373             26               0   \n",
      "22  T8GlYj2xDAs       16053         707            139               0   \n",
      "23  dggwhiuSkqU       72372        1786              0               0   \n",
      "24  T5BERlOouTY      141104        1353              0               0   \n",
      "25  vSrhCetz1gA       47177        1735             16               0   \n",
      "26  fzcxFTd9o3I       48592        1740              0               0   \n",
      "27  uZUuwaJLM10      271981       46445            490               0   \n",
      "28  _rwUsP3LF48      145314        4995             51               0   \n",
      "29  s2rQtoyKb0c       68972        6647            656               0   \n",
      "30  NPh1XB-n7q4       48749         352              0               0   \n",
      "31  -oVJ7zALvD8       79093       11455             52               0   \n",
      "32  uoqCKKQLiQY      908503       12553              0               0   \n",
      "33  i5cehh3wkVg       16550        1483             27               0   \n",
      "34  IfYdsEwTBkI       47673         582             11               0   \n",
      "35  VUIwbN2VTdE      122443        7652            956               0   \n",
      "36  HsQZE0iatg8      296143        5356           2159               0   \n",
      "37  rtLGwJF9Jxc       67000         524              0               0   \n",
      "38  OHd7DCBzCfE       37354        5428            288               0   \n",
      "39  N6Fo-gdaqTA       21009        2332             57               0   \n",
      "40  7gaoy3uyfik      444631       23043              0               0   \n",
      "41  HBTCZ4gEetY      721798       29983              0               0   \n",
      "42  c_jI07Nw2d0      116738        1254              0               0   \n",
      "43  UCak6RsyF_o        1138          20              0               0   \n",
      "44  o1Dn4hajLY8      487446        3078              0               0   \n",
      "45  EZXLSQDdeCk      845968       14591           1256               0   \n",
      "46  hSE0tzHS684       89804        4382            150               0   \n",
      "47  9hXbhuf-SzA       21197        1208             72               0   \n",
      "48  pD-ZHDaTm78      617457        4383            955               0   \n",
      "49  JEoLzhWp3mY     1970377       12506             34               0   \n",
      "\n",
      "      Video Category    Video Published At  \n",
      "0    News & Politics  2024-10-21T15:34:59Z  \n",
      "1             Gaming  2024-10-21T15:34:30Z  \n",
      "2   Film & Animation  2024-10-21T15:00:59Z  \n",
      "3    News & Politics  2024-10-21T15:01:13Z  \n",
      "4             Gaming  2024-10-21T14:56:19Z  \n",
      "5    News & Politics  2024-10-21T14:51:15Z  \n",
      "6             Gaming  2024-10-21T14:49:47Z  \n",
      "7   Film & Animation  2024-10-21T14:45:49Z  \n",
      "8    News & Politics  2024-10-21T14:29:42Z  \n",
      "9             Gaming  2024-10-21T14:20:19Z  \n",
      "10            Sports  2024-10-21T13:32:11Z  \n",
      "11     Entertainment  2024-10-21T13:30:50Z  \n",
      "12     Entertainment  2024-10-21T13:10:53Z  \n",
      "13    People & Blogs  2024-10-21T13:00:06Z  \n",
      "14   News & Politics  2024-10-21T12:52:07Z  \n",
      "15   News & Politics  2024-10-21T12:33:55Z  \n",
      "16   News & Politics  2024-10-21T11:46:55Z  \n",
      "17   News & Politics  2024-10-21T11:42:59Z  \n",
      "18   News & Politics  2024-10-21T11:44:14Z  \n",
      "19   News & Politics  2024-10-21T11:42:04Z  \n",
      "20     Entertainment  2024-10-21T11:31:13Z  \n",
      "21    People & Blogs  2024-10-21T11:30:13Z  \n",
      "22     Entertainment  2024-10-21T11:30:06Z  \n",
      "23   News & Politics  2024-10-21T11:25:21Z  \n",
      "24   News & Politics  2024-10-21T11:04:38Z  \n",
      "25     Entertainment  2024-10-21T10:33:18Z  \n",
      "26            Gaming  2024-10-21T10:33:18Z  \n",
      "27             Music  2024-10-21T10:30:21Z  \n",
      "28   News & Politics  2024-10-21T10:26:34Z  \n",
      "29            Sports  2024-10-21T10:01:02Z  \n",
      "30   News & Politics  2024-10-21T09:55:23Z  \n",
      "31    People & Blogs  2024-10-21T09:31:33Z  \n",
      "32   News & Politics  2024-10-21T09:30:22Z  \n",
      "33            Sports  2024-10-21T09:25:45Z  \n",
      "34  Film & Animation  2024-10-21T09:00:06Z  \n",
      "35   News & Politics  2024-10-21T08:57:54Z  \n",
      "36    People & Blogs  2024-10-21T08:52:08Z  \n",
      "37  Film & Animation  2024-10-21T08:20:14Z  \n",
      "38            Gaming  2024-10-21T08:04:26Z  \n",
      "39     Entertainment  2024-10-21T08:00:15Z  \n",
      "40    People & Blogs  2024-10-21T07:49:41Z  \n",
      "41     Entertainment  2024-10-21T07:48:16Z  \n",
      "42   News & Politics  2024-10-21T07:02:52Z  \n",
      "43     Entertainment  2024-10-21T05:07:16Z  \n",
      "44   News & Politics  2024-10-21T05:07:10Z  \n",
      "45            Sports  2024-10-21T05:04:56Z  \n",
      "46            Sports  2024-10-21T04:53:33Z  \n",
      "47            Sports  2024-10-21T04:51:20Z  \n",
      "48   News & Politics  2024-10-21T04:30:29Z  \n",
      "49            Sports  2024-10-21T04:19:39Z  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('YP_Youtube_50_Videos.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4015b584-69c3-42e5-871e-a0a945b718f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id0-2uhkaU0', 'M79F47l-qYc', 'uDVNRYxIMRE', 'Yfcs9OPrQz8', 'H_1-uFgQrrg', 'OapndFASEvk', 'VET1qKCyq4c', 'NUzGaZkGTu4', 'I1cPbwuMc3U', 'E98wLBO1v4I', 'RzQpDaa2044', 'GN0r5_ynJ9A', '_D3_9kIFUMs', 'ihtUyR9qjEs', '6iG4Zp8HLOA', 'p8SIBaDl9PE', 'IPwVtRypNbI', 'paTQ-p8K0BA', 'YhKkv5-4KAg', 'oUyle9aTwdI', 'LqIo3IwSWPY', 'Mq2M3Bz8zz0', 'T8GlYj2xDAs', 'dggwhiuSkqU', 'T5BERlOouTY', 'vSrhCetz1gA', 'fzcxFTd9o3I', 'uZUuwaJLM10', '_rwUsP3LF48', 's2rQtoyKb0c', 'NPh1XB-n7q4', '-oVJ7zALvD8', 'uoqCKKQLiQY', 'i5cehh3wkVg', 'IfYdsEwTBkI', 'VUIwbN2VTdE', 'HsQZE0iatg8', 'rtLGwJF9Jxc', 'OHd7DCBzCfE', 'N6Fo-gdaqTA', '7gaoy3uyfik', 'HBTCZ4gEetY', 'c_jI07Nw2d0', 'UCak6RsyF_o', 'o1Dn4hajLY8', 'EZXLSQDdeCk', 'hSE0tzHS684', '9hXbhuf-SzA', 'pD-ZHDaTm78', 'JEoLzhWp3mY']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the function to extract video IDs from the CSV with an optional parameter to limit the number of rows\n",
    "def get_video_ids_from_csv(file_path, n=None):\n",
    "    \"\"\"\n",
    "    Extract the first n video IDs from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        n (int, optional): Number of rows to extract. If None, extract all rows.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of video IDs.\n",
    "    \"\"\"\n",
    "    # Load the CSV into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # If n is provided, extract only the first n rows, otherwise extract all rows\n",
    "    if n:\n",
    "        video_ids = df['Video ID'].head(n).tolist()  # Extract first n rows\n",
    "    else:\n",
    "        video_ids = df['Video ID'].tolist()  # Extract all rows if n is not provided\n",
    "    \n",
    "    return video_ids\n",
    "\n",
    "# Example usage with your file path\n",
    "csv_file_path = '/Users/yipengandrewwang/DS3000-3/Project1/YP_Youtube_50_Videos.csv'\n",
    "\n",
    "#Extract only the first 10 video IDs\n",
    "video_ids_list = get_video_ids_from_csv(csv_file_path, n=50)\n",
    "print(video_ids_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471caad-fdaf-4075-ab76-9e48a92a672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for Session 1 (every 3 hours)...\n",
      "Session 1 data collected. Collected data for 50 videos.\n",
      "Waiting 2 hours before the next collection...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Initialize YouTube API client\n",
    "API_KEY = \"AIzaSyDOg4YBSWnZkOdsb67hDOVRsHuCht3TVDg\"  \n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "# Function to fetch video statistics for a list of video IDs\n",
    "def get_video_statistics(video_ids):\n",
    "    \"\"\"\n",
    "    This function fetches video statistics like views, likes, comments for a list of video IDs.\n",
    "    \n",
    "    Parameters:\n",
    "        video_ids (list): A list of video IDs for which to get statistics.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): The YouTube response containing the video statistics.\n",
    "    \"\"\"\n",
    "    request = youtube.videos().list(\n",
    "        part=\"statistics, snippet\",  # Get both statistics and metadata\n",
    "        id=\",\".join(video_ids)  # Join the video IDs into a comma-separated string\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "# The main function for collecting data every 30 minutes\n",
    "def collect_consecutive_sessions_data(video_ids, sessions=10, output_file=\"YP_Youtube_Consecutive_Sessions.csv\"):\n",
    "    \"\"\"\n",
    "    Collects video statistics for the same set of videos every 30 minutes over a specified number of sessions\n",
    "    and saves the results to a CSV file after each session.\n",
    "    \n",
    "    Parameters:\n",
    "        video_ids (list): List of video IDs for which to fetch statistics.\n",
    "        sessions (int): The number of consecutive 30-minute sessions to collect data (default is 10 sessions).\n",
    "        output_file (str): The name of the output CSV file to store the collected data.\n",
    "    \n",
    "    Returns:\n",
    "        None: The data is saved to the output CSV file after each session.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to store the data for all sessions\n",
    "    all_sessions_data = []\n",
    "    \n",
    "    # Collect data for each video over consecutive sessions (every 30 minutes)\n",
    "    for session in range(1, sessions + 1):\n",
    "        print(f\"Collecting data for Session {session} (every 3 hours)...\")\n",
    "        session_data = []  # Store data for each video in this session\n",
    "        \n",
    "        # Fetch statistics for the same video IDs\n",
    "        stats_response = get_video_statistics(video_ids)\n",
    "        \n",
    "        # Loop through each video and collect the stats for the current session\n",
    "        for item in stats_response.get('items', []):\n",
    "            video_id = item['id']\n",
    "            statistics = item['statistics']\n",
    "            snippet = item['snippet']\n",
    "            \n",
    "            # Store video stats for the current session\n",
    "            session_data.append({\n",
    "                'Video ID': video_id,\n",
    "                'Session': session,\n",
    "                'View Count': int(statistics.get('viewCount', 0)),\n",
    "                'Like Count': int(statistics.get('likeCount', 0)),\n",
    "                'Comment Count': int(statistics.get('commentCount', 0)),\n",
    "                'Favorite Count': int(statistics.get('favoriteCount', 0)),\n",
    "                'Video Category': snippet.get('categoryId', 'Unknown'),\n",
    "                'Video Published At': snippet.get('publishedAt', 'Unknown'),\n",
    "            })\n",
    "        \n",
    "        # Append the current session's data to the all_sessions_data list\n",
    "        all_sessions_data.extend(session_data)\n",
    "        \n",
    "        # Convert the collected data into a pandas DataFrame\n",
    "        df = pd.DataFrame(session_data)\n",
    "        \n",
    "        # Save the data to CSV file after each session (appending if it exists)\n",
    "        if session == 1:\n",
    "            # For the first session, write a new CSV file with the header\n",
    "            df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "        else:\n",
    "            # For subsequent sessions, append to the existing file without writing the header\n",
    "            df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "        \n",
    "        # Print summary of collected data for this session\n",
    "        print(f\"Session {session} data collected. Collected data for {len(session_data)} videos.\")\n",
    "        print(f\"Waiting 2 hours before the next collection...\")\n",
    "        \n",
    "        # Sleep for 3 hours before collecting the next session's data\n",
    "        time.sleep(2 * 60 * 60)  # Sleep for 2 hours\n",
    "\n",
    "# Example usage of the function\n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    sessions_to_collect = 18  # Collect data for 18 consecutive 2-hour sessions\n",
    "    \n",
    "    # Collect video data over consecutive sessions for the provided video IDs\n",
    "    collect_consecutive_sessions_data(video_ids_list, sessions=sessions_to_collect, output_file=\"YP_Youtube_Consecutive_Sessions4.csv\")\n",
    "    print(\"Data collection for consecutive 2-hour sessions complete. Saved to YP_Youtube_Consecutive_Sessions4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115e0c0-d54b-4656-8080-cd3cd1f3ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Built-in len function: {len}\")  # Check if len is still the built-in function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f671a3-5b63-4036-bd1a-db03e6e58439",
   "metadata": {},
   "outputs": [],
   "source": [
    "del len  # This will delete the overridden 'len' variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ae019-0745-4666-bb42-bf0851b2f962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e780a14-3055-46b5-b5d2-56da43e24a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06e1af13-3fac-457e-bdd5-3c6c3965dfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_dt_obj(string):\n",
    "    date_obj = datetime.strptime(string, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return date_obj\n",
    "\n",
    "str1 = '2024-10-17T15:36:09Z'\n",
    "str2 = '2024-10-13T15:36:09Z'\n",
    "\n",
    "date1 = convert_to_dt_obj(str1)\n",
    "date2 = convert_to_dt_obj(str2)\n",
    "\n",
    "print(date1>date2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9c6eed-c504-4807-a3d4-c8dc7468dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9-Q4DMC4Rs</td>\n",
       "      <td>1856</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68bWRSO8PYc</td>\n",
       "      <td>628</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yRIU2nzIQl8</td>\n",
       "      <td>4225</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_ZcBYWCDY</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ZLLfvPKTao</td>\n",
       "      <td>451</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "0  c9-Q4DMC4Rs        1856         139              0               0   \n",
       "1  68bWRSO8PYc         628          70              1               0   \n",
       "2  yRIU2nzIQl8        4225         132              0               0   \n",
       "3  BA_ZcBYWCDY         308          44              0               0   \n",
       "4  6ZLLfvPKTao         451          29              3               0   \n",
       "\n",
       "  Video Category    Video Published At  \n",
       "0      Education  2024-10-17T15:36:09Z  \n",
       "1      Education  2024-10-17T15:36:09Z  \n",
       "2      Education  2024-10-17T15:36:09Z  \n",
       "3      Education  2024-10-17T15:36:09Z  \n",
       "4      Education  2024-10-17T15:36:09Z  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('YP_Youtube1_4.csv',header=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b9614c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9-Q4DMC4Rs</td>\n",
       "      <td>1856</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68bWRSO8PYc</td>\n",
       "      <td>628</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yRIU2nzIQl8</td>\n",
       "      <td>4225</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_ZcBYWCDY</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ZLLfvPKTao</td>\n",
       "      <td>451</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "0  c9-Q4DMC4Rs        1856         139              0               0   \n",
       "1  68bWRSO8PYc         628          70              1               0   \n",
       "2  yRIU2nzIQl8        4225         132              0               0   \n",
       "3  BA_ZcBYWCDY         308          44              0               0   \n",
       "4  6ZLLfvPKTao         451          29              3               0   \n",
       "\n",
       "  Video Category   Video Published At  \n",
       "0      Education  2024-10-17 15:36:09  \n",
       "1      Education  2024-10-17 15:36:09  \n",
       "2      Education  2024-10-17 15:36:09  \n",
       "3      Education  2024-10-17 15:36:09  \n",
       "4      Education  2024-10-17 15:36:09  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = df.shape[0]\n",
    "for i in range(len):\n",
    "    df.loc[i,'Video Published At'] = convert_to_dt_obj(df['Video Published At'][i])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2728d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Video Published At'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2951b25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>KQkA8Qk_xjg</td>\n",
       "      <td>168</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>_gKU5DhYUn0</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Q8CeS_E_ewA</td>\n",
       "      <td>1832</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>ic74OdsEM0A</td>\n",
       "      <td>1758</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>7ZTWh6GGoPw</td>\n",
       "      <td>455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "4499  KQkA8Qk_xjg         168          16              0               0   \n",
       "4402  _gKU5DhYUn0         183           5              0               0   \n",
       "4401  Q8CeS_E_ewA        1832         130              0               0   \n",
       "4400  ic74OdsEM0A        1758           0              3               0   \n",
       "4399  7ZTWh6GGoPw         455           8              0               0   \n",
       "\n",
       "     Video Category   Video Published At  \n",
       "4499     Recreation  2024-09-18 15:36:09  \n",
       "4402     Recreation  2024-09-18 15:36:09  \n",
       "4401           Info  2024-09-18 15:36:09  \n",
       "4400           Info  2024-09-18 15:36:09  \n",
       "4399           Info  2024-09-18 15:36:09  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted = df.sort_values(by='Video Published At',ascending=True)\n",
    "sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43c8f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = {\n",
    "#     '1': 'Film & Animation',\n",
    "#     '2': 'Autos & Vehicles',\n",
    "#     '10': 'Music',\n",
    "#     '15': 'Pets & Animals',\n",
    "#     '17': 'Sports',\n",
    "#     '18': 'Short Movies',\n",
    "#     '19': 'Travel & Events',\n",
    "#     '20': 'Gaming',\n",
    "#     '21': 'Videoblogging',\n",
    "#     '22': 'People & Blogs',\n",
    "#     '23': 'Comedy',\n",
    "#     '24': 'Entertainment',\n",
    "#     '25': 'News & Politics',\n",
    "#     '26': 'Howto & Style',\n",
    "#     '27': 'Education',\n",
    "#     '28': 'Science & Technology',\n",
    "#     '29': 'Nonprofits & Activism'\n",
    "#     # More categories can be added here if needed, but this should cover the most common ones. I didn't find a better list/map yet if  you do you  can add here\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "227f20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recreation = ['Film & Animation','Music','Pets & Animals','Sports','Short Movies','Travel & Events',\\\n",
    "              'Gaming''Videoblogging','People & Blogs','Comedy','Entertainment'\n",
    "                ]\n",
    "\n",
    "info = ['News & Politics','Howto & Style','Education','Science & Technology','Nonprofits & Activism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50379790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9-Q4DMC4Rs</td>\n",
       "      <td>1856</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68bWRSO8PYc</td>\n",
       "      <td>628</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yRIU2nzIQl8</td>\n",
       "      <td>4225</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_ZcBYWCDY</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ZLLfvPKTao</td>\n",
       "      <td>451</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "0  c9-Q4DMC4Rs        1856         139              0               0   \n",
       "1  68bWRSO8PYc         628          70              1               0   \n",
       "2  yRIU2nzIQl8        4225         132              0               0   \n",
       "3  BA_ZcBYWCDY         308          44              0               0   \n",
       "4  6ZLLfvPKTao         451          29              3               0   \n",
       "\n",
       "  Video Category   Video Published At  \n",
       "0           Info  2024-10-17 15:36:09  \n",
       "1           Info  2024-10-17 15:36:09  \n",
       "2           Info  2024-10-17 15:36:09  \n",
       "3           Info  2024-10-17 15:36:09  \n",
       "4           Info  2024-10-17 15:36:09  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_categorize(string,recreation_list):\n",
    "    if string in recreation_list:\n",
    "        return 'Recreation'\n",
    "    else:\n",
    "        return 'Info'\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len):\n",
    "    df.loc[i,'Video Category'] = re_categorize(df['Video Category'][i],recreation)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "880a9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['Video Category'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
