{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e58fe91-3e39-4710-a18d-e04a7a8ddadf",
   "metadata": {},
   "source": [
    "# Project Proposal: Predicting the Popularity of YouTube Videos Using Early Metrics\n",
    "\n",
    "## 1. Problem Description and Motivation (2%)\n",
    "\n",
    "We want to predict how popular YouTube videos will be using early engagement metrics. YouTube's algorithm usually recommends videos based on early stats like views, likes, comments, and shares. But figuring out *which specific factors* have the biggest impact on whether a video goes viral can offer important insights for creators, marketers, and viewers.\n",
    "\n",
    "**Motivation**: With billions of videos on YouTube, knowing which ones will become popular early on can be super helpful for improving content strategy. This project will help people (and me! i have a pathetic youtube channel that nobody seems to notice) predict whether a video will be a hit by analyzing early data (like view count) .\n",
    "\n",
    "This is my channel i hope my project will help it one day :( ..... \n",
    "https://www.youtube.com/channel/UC91T6l13DPKKHhLMF10Gi2g?sub_confirmation=1\n",
    "\n",
    "We’re focusing on two key questions:\n",
    "1. **Which early engagement metrics (views, likes, comments) have the biggest influence on a video’s future success?**\n",
    "2. **Can we accurately predict the future view count of a video using data from its first 24 hours?**\n",
    "\n",
    "This project taps into the growing role of video content in today’s digital world and could be a valuable tool for content creators looking to improve their strategies.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b40d1-1622-4fb0-8544-1e1b3e4f68c7",
   "metadata": {},
   "source": [
    "## 2. Data Source and Collection Plan (2%)\n",
    "\n",
    "For this project, we’ll gather data using the **YouTube Data API**(very unfortunately it only allows us to collect `1500` videos per day. That's why i've consecutively collected datas for the past week so if you pick my proposal we will start with about at least `4500` videos. yay!). We’ll focus on videos uploaded in the last 30 days from a specific category (e.g., \"Data Science Tutorial\") to keep the data fresh and relevant.\n",
    "\n",
    "**Features we’ll collect:**\n",
    "- **Numeric Features**: View Count, Like Count, Comment Count\n",
    "- **Categorical Feature**: Video Category (e.g., \"Education,\" \"Science & Technology\")\n",
    "\n",
    "**Data Collection**: \n",
    "We’ll use Python and the YouTube Data API to collect the data. Each API call will retrieve up to 50 videos, and we’ll paginate through the results if needed. The data will be focused on engagement metrics ( we may later decide if we want the data to be collected only from the first 24 hours after the video is released by changing code here:  for day in range(days):  # Now we loop through each day to collect data\n",
    "        # We need to format the start and end dates correctly for YouTube's API\n",
    "        start_date = (today - timedelta(days=day+1)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end_date = (today - timedelta(days=day)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        )  We’ll map category IDs to their actual names to make the data easier to understand.\n",
    "\n",
    "We’ll store the data in a CSV file with the following columns:\n",
    "- `Video ID`: Unique identifier for each video\n",
    "- `View Count`: Number of views the video has received\n",
    "- `Like Count`: Number of likes\n",
    "- `Comment Count`: Number of comments\n",
    "- `Video Category`: The category the video belongs to\n",
    "- `Video Published At`: The date and time the video was published\n",
    "\n",
    "**I've paste my code below for ur referennce**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11381ce5-7293-424b-83f2-e369e1c8e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /opt/miniconda3/lib/python3.12/site-packages (2.147.0)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (2.35.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (2.20.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.28.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.24.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/miniconda3/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/miniconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535eda5-1b74-4d70-9315-3a85d45f5fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514d2165-63f4-41b3-8392-e8a63b1abb30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43013189-d456-4707-86f2-e64e3640a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection complete. Saved to YP_Youtube1_3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# Here's where I'm putting my YouTube API key. \n",
    "# (pls don't share it with others i have number limits every day on the videos i can pull off)\n",
    "API_KEY = \"AIzaSyDOg4YBSWnZkOdsb67hDOVRsHuCht3TVDg\"  \n",
    "\n",
    "# Now we initialize the YouTube API client with the API key so we can make requests\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "# Next, let's write a function to fetch videos based on a search query\n",
    "def get_videos(query, max_results=50, published_after=None, next_page_token=None):\n",
    "    \"\"\"\n",
    "    This function will fetch videos from YouTube based on the query we pass in.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The search term to find relevant videos.\n",
    "        max_results (int): The maximum number of videos to get in one request.\n",
    "        published_after (str): Only fetch videos published after this timestamp (formatted in RFC 3339).\n",
    "        next_page_token (str): Here we use pagination to fetch more videos, if available.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): This will return the YouTube response with video data.\n",
    "    \"\"\"\n",
    "    request = youtube.search().list(\n",
    "        q=query,  # Here we set the search term\n",
    "        part=\"snippet\",  # Now we can get the basic info about each video (like title, channel, etc.)\n",
    "        type=\"video\",  # This will get only videos (not channels or playlists)\n",
    "        maxResults=max_results,  # This controls how many videos we’re requesting in this call\n",
    "        publishedAfter=published_after,  # Only fetch videos after a certain date\n",
    "        order=\"relevance\",  # This sorts the videos by relevance to our query\n",
    "        pageToken=next_page_token  # If there are more pages, this will help us get the next set of results\n",
    "    )\n",
    "    response = request.execute()  # Now we execute the request to YouTube\n",
    "    return response  # Here we return the fetched video data\n",
    "\n",
    "# Now we can write a function to get the stats for each video (e.g., views, likes, comments)\n",
    "def get_video_statistics(video_ids):\n",
    "    \"\"\"\n",
    "    This function will grab all the stats for the videos we found, including category information.\n",
    "    \n",
    "    Parameters:\n",
    "        video_ids (list): A list of video IDs for which to get statistics.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): This returns the video statistics and metadata from YouTube.\n",
    "    \"\"\"\n",
    "    request = youtube.videos().list(\n",
    "        part=\"statistics, snippet\",  # Now we can fetch both statistics (views, likes) and snippet (title, category)\n",
    "        id=\",\".join(video_ids)  # Here we join the video IDs into a single string separated by commas\n",
    "    )\n",
    "    response = request.execute()  # Now we execute the request to get the stats\n",
    "    return response  # Finally, we return the response containing video stats\n",
    "\n",
    "# This is the main function that collects video data over a number of days\n",
    "def collect_video_data(query, days=30, max_results_per_day=50, max_total_results_per_day=100):\n",
    "    \"\"\"\n",
    "    Here we collect video data for a specific search query over several days.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The search query to find relevant videos.\n",
    "        days (int): The number of days to collect video data.\n",
    "        max_results_per_day (int): Maximum videos to fetch per request (per day).\n",
    "        max_total_results_per_day (int): The total number of videos to fetch per day, including paginated results.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Now we’ll return a DataFrame with all the collected video statistics and metadata.\n",
    "    \"\"\"\n",
    "    video_data = []\n",
    "    today = datetime.now(timezone.utc)  # Here we get the current date and time in UTC to work with timestamps\n",
    "    \n",
    "    for day in range(days):  # Now we loop through each day to collect data\n",
    "        # We need to format the start and end dates correctly for YouTube's API\n",
    "        start_date = (today - timedelta(days=day+1)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end_date = (today - timedelta(days=day)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        \n",
    "        next_page_token = None  # Initialize the page token for pagination\n",
    "        total_results_fetched = 0  # Keep track of how many results we’ve fetched so far\n",
    "        \n",
    "        # Now we loop until we've fetched the total results for the day\n",
    "        while total_results_fetched < max_total_results_per_day:\n",
    "            # Fetch the videos published after the start date\n",
    "            response = get_videos(query, max_results=max_results_per_day, published_after=start_date, next_page_token=next_page_token)\n",
    "            \n",
    "            video_ids = [item['id']['videoId'] for item in response.get('items', [])]  # Extract video IDs from the response\n",
    "            \n",
    "            if not video_ids:\n",
    "                break  # If no videos are found, we stop for this day\n",
    "            \n",
    "            # Now we can get the stats for each video\n",
    "            stats_response = get_video_statistics(video_ids)\n",
    "            \n",
    "            # Next, we loop through each video and collect the data\n",
    "            for item in stats_response.get('items', []):\n",
    "                video_id = item['id']\n",
    "                statistics = item['statistics']  # Get the statistics like views, likes, etc.\n",
    "                snippet = item['snippet']  # Grab the metadata like title and category\n",
    "                \n",
    "                # Now we add the collected data to our list\n",
    "                video_data.append({\n",
    "                    'Video ID': video_id,\n",
    "                    'View Count': int(statistics.get('viewCount', 0)),  # Make sure view count is an integer, defaulting to 0 if missing\n",
    "                    'Like Count': int(statistics.get('likeCount', 0)),  # Same for like count\n",
    "                    'Comment Count': int(statistics.get('commentCount', 0)),  # And for comment count\n",
    "                    'Favorite Count': int(statistics.get('favoriteCount', 0)),  # Handle favorite count similarly\n",
    "                    'Video Category': snippet.get('categoryId', 'Unknown'),  # We store the category ID as a categorical feature\n",
    "                    'Video Published At': start_date  # Store the date the video was published\n",
    "                })\n",
    "            \n",
    "            # Update the total number of results we've fetched\n",
    "            total_results_fetched += len(video_ids)\n",
    "            \n",
    "            # Check if there is another page of results to fetch\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break  # If there are no more pages, we're done here\n",
    "    \n",
    "    # Finally, convert the list of video data into a DataFrame\n",
    "    return pd.DataFrame(video_data)\n",
    "\n",
    "# Now we can use all of this to collect data and save it to a CSV\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Data Science Tutorial\"  # Set the search term to something relevant (e.g., \"Data Science Tutorial\")\n",
    "    days_to_collect = 30  # Collect data for the last 30 days\n",
    "    max_videos_per_day = 50  # Fetch up to 50 videos in one request\n",
    "    max_total_results_per_day = 150  # Fetch up to 150 videos in total per day (with pagination)\n",
    "    \n",
    "    # Time to collect our video data\n",
    "    df = collect_video_data(query, days=days_to_collect, max_results_per_day=max_videos_per_day, max_total_results_per_day=max_total_results_per_day)\n",
    "    \n",
    "    # Now we save the collected data to a CSV file\n",
    "    df.to_csv('YP_Youtube1_3.csv', index=False)\n",
    "    print(\"Data collection complete. Saved to YP_Youtube1_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b62008-5c9a-4083-ac34-0b320b413cbc",
   "metadata": {},
   "source": [
    "While gathering the data from YouTube, I encountered an issue where the \"Video Category\" field was returned in numerical format. These numerical category IDs aren't very helpful for understanding what each category represents. I dopn't think the youtube API i am using natively support category names.\n",
    "\n",
    "To make the data more meaningful and readable, we need to map these numerical category IDs to their actual category names (e.g., '27' becomes 'Education', '28' becomes 'Science & Technology', and so on).\n",
    "\n",
    "In the next step, I create a dictionary to map these numerical IDs to their corresponding names, then apply this mapping to the dataset so that the \"Video Category\" field reflects the actual category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1f7f15-2903-4a5a-9e2f-8ce5f28d895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category mapping completed. Saved to YP_Youtube1_4.csv\n"
     ]
    }
   ],
   "source": [
    "# Now, we're going to create a dictionary to map those category IDs to actual category names. \n",
    "# This way, we can easily understand what each category represents.\n",
    "category_mapping = {\n",
    "    '1': 'Film & Animation',\n",
    "    '2': 'Autos & Vehicles',\n",
    "    '10': 'Music',\n",
    "    '15': 'Pets & Animals',\n",
    "    '17': 'Sports',\n",
    "    '18': 'Short Movies',\n",
    "    '19': 'Travel & Events',\n",
    "    '20': 'Gaming',\n",
    "    '21': 'Videoblogging',\n",
    "    '22': 'People & Blogs',\n",
    "    '23': 'Comedy',\n",
    "    '24': 'Entertainment',\n",
    "    '25': 'News & Politics',\n",
    "    '26': 'Howto & Style',\n",
    "    '27': 'Education',\n",
    "    '28': 'Science & Technology',\n",
    "    '29': 'Nonprofits & Activism'\n",
    "    # More categories can be added here if needed, but this should cover the most common ones. I didn't find a better list/map yet if  you do you  can add here\n",
    "}\n",
    "\n",
    "# Now let's load the CSV file that contains our YouTube video data.\n",
    "# This file has all the video details that we collected earlier.\n",
    "df = pd.read_csv('YP_Youtube1_3.csv')\n",
    "\n",
    "# Here's where the transformation happens. We're going to replace the category IDs with the actual names.\n",
    "# First, we make sure the 'Video Category' column is in string format, then we map those IDs to the category names.\n",
    "df['Video Category'] = df['Video Category'].astype(str).map(category_mapping)\n",
    "\n",
    "# Now that we've updated the data, let's save it to a new CSV file.\n",
    "# This way, the original data stays untouched, and we get a more readable version with category names.\n",
    "df.to_csv('YP_Youtube1_4.csv', index=False)\n",
    "\n",
    "# Finally, let's print a message to confirm that everything worked and the file was saved successfully.\n",
    "print(\"Category mapping completed. Saved to YP_Youtube1_4.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22c2c6-c344-4c35-903a-479ef0109063",
   "metadata": {},
   "source": [
    "  ## 3. How the Data Will Be Used and Questions of Interest (1%)\n",
    "\n",
    "Once we have the data, we’ll analyze how early engagement metrics relate to a video’s future popularity. Specifically, we’ll focus on:\n",
    "\n",
    "- **Predicting View Counts**: Using the early metrics (views, likes, comments), we’ll try to predict how many views a video will get in the future (like a week later). By building a machine learning model, we’ll look for patterns that can predict future video performance.\n",
    "  \n",
    "- **Identifying Key Metrics**: We’ll also try to figure out which engagement metric has the biggest influence on a video’s popularity. For example, is the number of comments more important than the number of likes?\n",
    "\n",
    "The goal is to create a model that helps us understand and predict how successful a video will be based on its early performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This project dives into the growing trend of using early data to predict video success on YouTube. By collecting and analyzing video data over time, we hope to uncover useful insights for content creators and marketers. Plus, it’s a great way to apply machine learning techniques to real-world data from one of the biggest video platforms in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f745daeb-489c-4a85-9e78-0c6403210090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c9-Q4DMC4Rs', '68bWRSO8PYc', 'yRIU2nzIQl8', 'BA_ZcBYWCDY', '6ZLLfvPKTao', 'FxlHVQa5l5Q', '0DKr3ms2bg0', 'TxkR4o_m3ls', 'eutTuyQesk4', 'T6RjbPMlpYQ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the function to extract video IDs from the CSV with an optional parameter to limit the number of rows\n",
    "def get_video_ids_from_csv(file_path, n=None):\n",
    "    \"\"\"\n",
    "    Extract the first n video IDs from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        n (int, optional): Number of rows to extract. If None, extract all rows.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of video IDs.\n",
    "    \"\"\"\n",
    "    # Load the CSV into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # If n is provided, extract only the first n rows, otherwise extract all rows\n",
    "    if n:\n",
    "        video_ids = df['Video ID'].head(n).tolist()  # Extract first n rows\n",
    "    else:\n",
    "        video_ids = df['Video ID'].tolist()  # Extract all rows if n is not provided\n",
    "    \n",
    "    return video_ids\n",
    "\n",
    "# Example usage with your file path\n",
    "csv_file_path = '/Users/yipengandrewwang/DS3000-3/Project1/YP_Youtube1_4.csv'\n",
    "\n",
    "# Extract only the first 10 video IDs\n",
    "video_ids_list = get_video_ids_from_csv(csv_file_path, n=10)\n",
    "print(video_ids_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb577fc3-c430-4f8f-9d0f-809e978dc9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471caad-fdaf-4075-ab76-9e48a92a672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for Session 1 (every 30 minutes)...\n",
      "Session 1 data collected. Collected data for 10 videos.\n",
      "Waiting 10 minutes before the next collection...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Initialize YouTube API client\n",
    "API_KEY = \"AIzaSyDOg4YBSWnZkOdsb67hDOVRsHuCht3TVDg\"  # Replace with your actual API key\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "# Function to fetch video statistics for a list of video IDs\n",
    "def get_video_statistics(video_ids):\n",
    "    \"\"\"\n",
    "    This function fetches video statistics like views, likes, comments for a list of video IDs.\n",
    "    \n",
    "    Parameters:\n",
    "        video_ids (list): A list of video IDs for which to get statistics.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): The YouTube response containing the video statistics.\n",
    "    \"\"\"\n",
    "    request = youtube.videos().list(\n",
    "        part=\"statistics, snippet\",  # Get both statistics and metadata\n",
    "        id=\",\".join(video_ids)  # Join the video IDs into a comma-separated string\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "# The main function for collecting data every 30 minutes\n",
    "def collect_consecutive_sessions_data(video_ids, sessions=10):\n",
    "    \"\"\"\n",
    "    Collects video statistics for the same set of videos every 30 minutes over a specified number of sessions.\n",
    "    \n",
    "    Parameters:\n",
    "        video_ids (list): List of video IDs for which to fetch statistics.\n",
    "        sessions (int): The number of consecutive 30-minute sessions to collect data (default is 10 sessions).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing video statistics over multiple sessions for each video.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to store the data for all sessions\n",
    "    all_sessions_data = []\n",
    "\n",
    "    # Collect data for each video over consecutive sessions (every 30 minutes)\n",
    "    for session in range(1, sessions + 1):\n",
    "        print(f\"Collecting data for Session {session} (every 30 minutes)...\")\n",
    "        session_data = []  # Store data for each video in this session\n",
    "        \n",
    "        # Fetch statistics for the same video IDs\n",
    "        stats_response = get_video_statistics(video_ids)\n",
    "        \n",
    "        # Loop through each video and collect the stats for the current session\n",
    "        for item in stats_response.get('items', []):\n",
    "            video_id = item['id']\n",
    "            statistics = item['statistics']\n",
    "            snippet = item['snippet']\n",
    "            \n",
    "            # Store video stats for the current session\n",
    "            session_data.append({\n",
    "                'Video ID': video_id,\n",
    "                'Session': session,\n",
    "                'View Count': int(statistics.get('viewCount', 0)),\n",
    "                'Like Count': int(statistics.get('likeCount', 0)),\n",
    "                'Comment Count': int(statistics.get('commentCount', 0)),\n",
    "                'Favorite Count': int(statistics.get('favoriteCount', 0)),\n",
    "                'Video Category': snippet.get('categoryId', 'Unknown'),\n",
    "                'Video Published At': snippet.get('publishedAt', 'Unknown'),\n",
    "            })\n",
    "        \n",
    "        # Append the current session's data to the all_sessions_data list\n",
    "        all_sessions_data.extend(session_data)\n",
    "        \n",
    "        # Print summary of collected data for this session\n",
    "        print(f\"Session {session} data collected. Collected data for {len(session_data)} videos.\")\n",
    "        print(f\"Waiting 10 minutes before the next collection...\")\n",
    "        \n",
    "        # Sleep for 30 minutes before collecting the next session's data\n",
    "        time.sleep(10 * 60)  # Sleep for 10 minutes\n",
    "    \n",
    "    # Convert the collected data into a pandas DataFrame\n",
    "    df = pd.DataFrame(all_sessions_data)\n",
    "    \n",
    "    # Return the final DataFrame containing stats for each video over the sessions\n",
    "    return df\n",
    "\n",
    "# Example usage of the function\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    sessions_to_collect = 10  # Collect data for 10 consecutive 10-minute sessions\n",
    "    \n",
    "    # Collect video data over consecutive sessions for the provided video IDs\n",
    "    df = collect_consecutive_sessions_data(video_ids_list, sessions=sessions_to_collect)\n",
    "    \n",
    "    # Save the collected data to a CSV file\n",
    "    df.to_csv('YP_Youtube_Consecutive_Sessions2.csv', index=False)\n",
    "    print(\"Data collection for consecutive 10-minute sessions complete. Saved to YP_Youtube_Consecutive_Sessions2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4115e0c0-d54b-4656-8080-cd3cd1f3ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built-in len function: 245\n"
     ]
    }
   ],
   "source": [
    "print(f\"Built-in len function: {len}\")  # Check if len is still the built-in function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2f671a3-5b63-4036-bd1a-db03e6e58439",
   "metadata": {},
   "outputs": [],
   "source": [
    "del len  # This will delete the overridden 'len' variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ae019-0745-4666-bb42-bf0851b2f962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e780a14-3055-46b5-b5d2-56da43e24a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06e1af13-3fac-457e-bdd5-3c6c3965dfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_dt_obj(string):\n",
    "    date_obj = datetime.strptime(string, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return date_obj\n",
    "\n",
    "str1 = '2024-10-17T15:36:09Z'\n",
    "str2 = '2024-10-13T15:36:09Z'\n",
    "\n",
    "date1 = convert_to_dt_obj(str1)\n",
    "date2 = convert_to_dt_obj(str2)\n",
    "\n",
    "print(date1>date2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9c6eed-c504-4807-a3d4-c8dc7468dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9-Q4DMC4Rs</td>\n",
       "      <td>1856</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68bWRSO8PYc</td>\n",
       "      <td>628</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yRIU2nzIQl8</td>\n",
       "      <td>4225</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_ZcBYWCDY</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ZLLfvPKTao</td>\n",
       "      <td>451</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17T15:36:09Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "0  c9-Q4DMC4Rs        1856         139              0               0   \n",
       "1  68bWRSO8PYc         628          70              1               0   \n",
       "2  yRIU2nzIQl8        4225         132              0               0   \n",
       "3  BA_ZcBYWCDY         308          44              0               0   \n",
       "4  6ZLLfvPKTao         451          29              3               0   \n",
       "\n",
       "  Video Category    Video Published At  \n",
       "0      Education  2024-10-17T15:36:09Z  \n",
       "1      Education  2024-10-17T15:36:09Z  \n",
       "2      Education  2024-10-17T15:36:09Z  \n",
       "3      Education  2024-10-17T15:36:09Z  \n",
       "4      Education  2024-10-17T15:36:09Z  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('YP_Youtube1_4.csv',header=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b9614c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9-Q4DMC4Rs</td>\n",
       "      <td>1856</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68bWRSO8PYc</td>\n",
       "      <td>628</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yRIU2nzIQl8</td>\n",
       "      <td>4225</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_ZcBYWCDY</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ZLLfvPKTao</td>\n",
       "      <td>451</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "0  c9-Q4DMC4Rs        1856         139              0               0   \n",
       "1  68bWRSO8PYc         628          70              1               0   \n",
       "2  yRIU2nzIQl8        4225         132              0               0   \n",
       "3  BA_ZcBYWCDY         308          44              0               0   \n",
       "4  6ZLLfvPKTao         451          29              3               0   \n",
       "\n",
       "  Video Category   Video Published At  \n",
       "0      Education  2024-10-17 15:36:09  \n",
       "1      Education  2024-10-17 15:36:09  \n",
       "2      Education  2024-10-17 15:36:09  \n",
       "3      Education  2024-10-17 15:36:09  \n",
       "4      Education  2024-10-17 15:36:09  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = df.shape[0]\n",
    "for i in range(len):\n",
    "    df.loc[i,'Video Published At'] = convert_to_dt_obj(df['Video Published At'][i])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2728d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Video Published At'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2951b25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>KQkA8Qk_xjg</td>\n",
       "      <td>168</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>_gKU5DhYUn0</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Q8CeS_E_ewA</td>\n",
       "      <td>1832</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>ic74OdsEM0A</td>\n",
       "      <td>1758</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>7ZTWh6GGoPw</td>\n",
       "      <td>455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-09-18 15:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "4499  KQkA8Qk_xjg         168          16              0               0   \n",
       "4402  _gKU5DhYUn0         183           5              0               0   \n",
       "4401  Q8CeS_E_ewA        1832         130              0               0   \n",
       "4400  ic74OdsEM0A        1758           0              3               0   \n",
       "4399  7ZTWh6GGoPw         455           8              0               0   \n",
       "\n",
       "     Video Category   Video Published At  \n",
       "4499     Recreation  2024-09-18 15:36:09  \n",
       "4402     Recreation  2024-09-18 15:36:09  \n",
       "4401           Info  2024-09-18 15:36:09  \n",
       "4400           Info  2024-09-18 15:36:09  \n",
       "4399           Info  2024-09-18 15:36:09  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted = df.sort_values(by='Video Published At',ascending=True)\n",
    "sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43c8f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = {\n",
    "#     '1': 'Film & Animation',\n",
    "#     '2': 'Autos & Vehicles',\n",
    "#     '10': 'Music',\n",
    "#     '15': 'Pets & Animals',\n",
    "#     '17': 'Sports',\n",
    "#     '18': 'Short Movies',\n",
    "#     '19': 'Travel & Events',\n",
    "#     '20': 'Gaming',\n",
    "#     '21': 'Videoblogging',\n",
    "#     '22': 'People & Blogs',\n",
    "#     '23': 'Comedy',\n",
    "#     '24': 'Entertainment',\n",
    "#     '25': 'News & Politics',\n",
    "#     '26': 'Howto & Style',\n",
    "#     '27': 'Education',\n",
    "#     '28': 'Science & Technology',\n",
    "#     '29': 'Nonprofits & Activism'\n",
    "#     # More categories can be added here if needed, but this should cover the most common ones. I didn't find a better list/map yet if  you do you  can add here\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "227f20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recreation = ['Film & Animation','Music','Pets & Animals','Sports','Short Movies','Travel & Events',\\\n",
    "              'Gaming''Videoblogging','People & Blogs','Comedy','Entertainment'\n",
    "                ]\n",
    "\n",
    "info = ['News & Politics','Howto & Style','Education','Science & Technology','Nonprofits & Activism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50379790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Video Category</th>\n",
       "      <th>Video Published At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9-Q4DMC4Rs</td>\n",
       "      <td>1856</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68bWRSO8PYc</td>\n",
       "      <td>628</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yRIU2nzIQl8</td>\n",
       "      <td>4225</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_ZcBYWCDY</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ZLLfvPKTao</td>\n",
       "      <td>451</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Info</td>\n",
       "      <td>2024-10-17 15:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID  View Count  Like Count  Comment Count  Favorite Count  \\\n",
       "0  c9-Q4DMC4Rs        1856         139              0               0   \n",
       "1  68bWRSO8PYc         628          70              1               0   \n",
       "2  yRIU2nzIQl8        4225         132              0               0   \n",
       "3  BA_ZcBYWCDY         308          44              0               0   \n",
       "4  6ZLLfvPKTao         451          29              3               0   \n",
       "\n",
       "  Video Category   Video Published At  \n",
       "0           Info  2024-10-17 15:36:09  \n",
       "1           Info  2024-10-17 15:36:09  \n",
       "2           Info  2024-10-17 15:36:09  \n",
       "3           Info  2024-10-17 15:36:09  \n",
       "4           Info  2024-10-17 15:36:09  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_categorize(string,recreation_list):\n",
    "    if string in recreation_list:\n",
    "        return 'Recreation'\n",
    "    else:\n",
    "        return 'Info'\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len):\n",
    "    df.loc[i,'Video Category'] = re_categorize(df['Video Category'][i],recreation)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "880a9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['Video Category'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
